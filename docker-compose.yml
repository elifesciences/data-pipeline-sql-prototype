version: '3'

services:
    wheels:
        build:
            context: .
            dockerfile: Dockerfile.wheels
        image: elifesciences/data-pipeline-wheels:${IMAGE_TAG}
    airflow:
        build:
            context: ./airflow
            args:
                IMAGE_TAG: ${IMAGE_TAG}
        image: elifesciences/data-pipeline-airflow:${IMAGE_TAG}
        depends_on:
            - wheels
    airflow-flower:
        image: elifesciences/data-pipeline-airflow:${IMAGE_TAG}
        depends_on:
            - airflow
            - airflow-redis
        environment:
            - EXECUTOR=Celery
            - REDIS_HOST=airflow-redis
        ports:
            - "5555:5555"
        command: flower
    airflow-postgres:
        image: postgres:9.6.8-alpine
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - PGDATA=/var/lib/postgresql/data
        volumes:
            - airflow-postgres:/var/lib/postgresql/data
    airflow-redis:
        image: 'redis:3.2.7'
    airflow-scheduler:
        image: elifesciences/data-pipeline-airflow:${IMAGE_TAG}
        depends_on:
            - airflow
            - airflow-webserver
        environment:
            - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
            - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_HOST=airflow-postgres
            - REDIS_HOST=airflow-redis
        command: scheduler
    airflow-webserver:
        image: elifesciences/data-pipeline-airflow:${IMAGE_TAG}
        depends_on:
            - airflow
            - airflow-postgres
            - airflow-redis
        environment:
            - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
            - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_HOST=airflow-postgres
            - REDIS_HOST=airflow-redis
        ports:
            - "8086:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3
    airflow-worker:
        image: elifesciences/data-pipeline-airflow:${IMAGE_TAG}
        depends_on:
            - airflow
            - airflow-scheduler
        environment:
            - ARCHIVE_BUCKET=$ARCHIVE_BUCKET
            - INCOMING_BUCKET=$INCOMING_BUCKET
            - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
            - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_HOST=airflow-postgres
            - REDIS_HOST=airflow-redis
            - DATA_PIPELINE_DATABASE_HOST=$DATA_PIPELINE_DATABASE_HOST
            - DATA_PIPELINE_DATABASE_PORT=$DATA_PIPELINE_DATABASE_PORT
            - DATA_PIPELINE_DATABASE_NAME=$DATA_PIPELINE_DATABASE_NAME
            - DATA_PIPELINE_DATABASE_USER=$DATA_PIPELINE_DATABASE_USER
            - DATA_PIPELINE_DATABASE_PASSWORD=$DATA_PIPELINE_DATABASE_PASSWORD
        command: worker

    db:
        image: postgres:9.6
        restart: always
        volumes:
            - postgres-data:/var/lib/postgresql/data
        environment:
            POSTGRES_DB: $DATA_PIPELINE_DATABASE_NAME
            POSTGRES_USER: $DATA_PIPELINE_DATABASE_USER
            POSTGRES_PASSWORD: $DATA_PIPELINE_DATABASE_PASSWORD
        healthcheck:
            test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/5432"]
            interval: 10s
            timeout: 10s
            retries: 5

    db-test:
        image: postgres:9.6
        restart: always
        tmpfs:
            - /var/lib/postgresql/data
        ports:
            - "9432:5432"
        environment:
            POSTGRES_DB: test
            POSTGRES_USER: test
            POSTGRES_PASSWORD: test
        healthcheck:
            test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/5432"]
            interval: 10s
            timeout: 10s
            retries: 5

    csv-generator:
        build:
            context: ./csv-generator
        command: '--help'
        image: data-pipeline/csv-generator:${IMAGE_TAG}
        volumes:
            - ./example-data:/example-data
            - xml-data:/xml-data
            - ./csv-data:/csv-data

    db-manager:
        build:
            context: ./db-manager
        command: ''
        image: data-pipeline/db-manager:${IMAGE_TAG}
        depends_on:
            - db
            - db-test
        volumes:
            - ./db-manager/dummy_csv:/dummy_csv
            - csv-data:/csv-data
        environment:
            DATA_PIPELINE_DATABASE_HOST: db
            DATA_PIPELINE_DATABASE_PORT: 5432
            DATA_PIPELINE_DATABASE_NAME: $DATA_PIPELINE_DATABASE_NAME
            DATA_PIPELINE_DATABASE_USER: $DATA_PIPELINE_DATABASE_USER
            DATA_PIPELINE_DATABASE_PASSWORD: $DATA_PIPELINE_DATABASE_PASSWORD
            DATA_PIPELINE_TEST_DATABASE_HOST: db-test
            DATA_PIPELINE_TEST_DATABASE_PORT: 5432

volumes:
    airflow-postgres:
    postgres-data:
    xml-data: 
    csv-data:
